# Optimal control using Dynamic Programming

<h1><b> Overview </b></h1>
This project focuses on path planning and the development of optimal control policies for robots or agents. Path planning involves finding a route from a starting location to a goal location while avoiding obstacles. Optimal control policies aim to minimize a cost function, such as energy consumption or task completion time, and are crucial for resource-efficient autonomous robots. The project implements a Dynamic Programming algorithm for autonomous navigation in a Door, Key, and Goal environment. <br>
The objective is to guide an agent to the goal while considering the possibility of encountering a closed door that requires a key to unlock. The project addresses both known and random map scenarios, calculating control policies for different environments. The results showcase the effectiveness of the proposed approach in calculating optimal control policies and demonstrate its potential application in autonomous navigation in complex environments.

